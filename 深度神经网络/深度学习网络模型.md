# 深度神经网络模型

2017211303班 2017211146 张静雅

## 一、问题描述

**问题：**我们将仅根据鸢尾花花萼和花瓣的长度和宽度对其分为三类：山鸢尾 变色鸢尾 维吉尼亚鸢尾 。为了预测看到的鸢尾花究竟属于哪一类。

**条件**：我们已经创建了一个包含 120 株鸢尾花的数据集，数据集前5个条目如下：

| 花萼长度 | 花萼宽度 | 花瓣长度 | 花瓣宽度 | 品种 |
| -------- | -------- | -------- | -------- | ---- |
| 6.4      | 2.8      | 5.6      | 2.2      | 2    |
| 5.0      | 2.3      | 3.3      | 1.0      | 1    |
| 4.9      | 2.5      | 4.5      | 1.7      | 2    |
| 4.9      | 3.1      | 1.5      | 0.1      | 0    |
| 5.7      | 3.8      | 1.7      | 0.3      | 0    |

0代表setosa(山鸢尾)

1代表versicolor(变色鸢尾)

2代表virginica(维吉尼亚鸢尾)

## 二、深度网络模型结构图

<img src="D:\google下载\未命名绘图.png" style="zoom: 67%;" />

![image-20200613221128977](C:\Users\zjy\AppData\Roaming\Typora\typora-user-images\image-20200613221128977.png)

## 三、损失函数

使用计算交叉熵：

交叉熵（Cross Entropy）是Loss函数的一种（也称为损失函数或代价函数），用于描述模型预测值与真实值的差距大小，常见的Loss函数就是**均方平方差**（Mean Squared Error），定义如下。

![img](https://upload-images.jianshu.io/upload_images/5877934-d7a5152da2c89f8f.png?imageMogr2/auto-orient/strip|imageView2/2/w/220/format/webp)

实际上，交叉熵是衡量两个概率分布p，q之间的相似性，两个分布越相似(即越精确)交叉熵就会越小。

```python
    # 损失函数，使用的是交叉熵
    def loss(model, x, y):
        y_ = model(x)
        return tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)

```

参数：

- labels：一个长度为batch_size的一维张量，真实的标签索引，每一个元素对应logits中的一行。

- logits：形状为[batch_size，num_classes]的张量，神经网络的输出。

- 作用：计算神经网络的输出于真实标签的交叉熵。

  

计算方式：对输入的logits先通过softmax函数计算，再计算它们的交叉熵，但是它对交叉熵的计算方式进行了优化，使得结果不至于溢出。

计算过程：

* 第一步：Softmax计算。对logits的每一行进行归一化(或概率化)的softmax操作，计算公式如下：X为logits的某一行。

  <img src="C:\Users\zjy\AppData\Roaming\Typora\typora-user-images\image-20200613220535593.png" alt="image-20200613220535593" style="zoom: 50%;" />

* 第二步：计算Cross-Entropy。计算第一步正则化后的logits于label的交叉熵：由于label格式为一维的向量，所以首先需要将其转化为one-hot格式的编码格式。再计算交叉熵(公式如下)：

  <img src="C:\Users\zjy\AppData\Roaming\Typora\typora-user-images\image-20200613220614257.png" alt="image-20200613220614257" style="zoom:50%;" />

## 四、训练、测试数据集

训练集：如图120个数据

属性分别为：花萼长度  花萼宽度  花瓣长度  花瓣宽度  品种

![image-20200610030608422](C:\Users\zjy\AppData\Roaming\Typora\typora-user-images\image-20200610030608422.png)

测试数据集：如图所示30个数据

属性分别为：花萼长度  花萼宽度  花瓣长度  花瓣宽度  品种

![image-20200613154623466](C:\Users\zjy\AppData\Roaming\Typora\typora-user-images\image-20200613154623466.png)

## 五、训练方法

1.搭建神经网络

```python
class NNetConfig():
    num_classes = 3  # 多分类的种类
    num_epochs = 161  # 训练总批次
    print_per_epoch = 20  # 每训练多少批次时打印训练损失函数值和预测准确率值
    layersls = [4, 10, 20, 10, 3]  # 【输入，隐藏各层节点数，输出】
    learning_rate = 0.01  # 网络学习率
    train_filename = './data/iris_training.csv'  # 训练数据
    test_filename = './data/iris_test.csv'  # 测试数据
    best_model_savepath = "./dnn/best_validation"   # 最好模型的存放文件夹

class NNet(object):
    def __init__(self, config):
        self.config = config
        self.layersls = config.layersls
        self.NNet()

    def NNet(self): # 根据给出的输入输出及每层网络的节点数搭建深度学习网络
        """
        根据给出的输入输出及每层网络的节点数搭建深度学习网络
        :param layersls: 【输入，隐藏各层节点数，输出】
        :return:
        """
        model = tf.keras.Sequential()
        for i in range(len(config.layersls)):
            if(i == 0):     # 确定网络的输入和网络的第一层节点数
                model.add(tf.keras.layers.Dense(config.layersls[1],
                                                activation="relu",
                                                input_shape=(config.layersls[0],)))
                i += 1
            elif(i == len(config.layersls)-1): # 确定网络的输出
                model.add(tf.keras.layers.Dense(config.layersls[i]))
            else:  # 网络的各隐藏层节点数
                model.add(tf.keras.layers.Dense(config.layersls[i],
                                                activation="relu"))
        return model

```

2.获取训练数据

3.定义网络优化器：以一定速率进行网络训练的优化

```python
 optimizer = tf.compat.v1.train.GradientDescentOptimizer(config.learning_rate)
```

4.计算当前批次训练的损失函数均值，预测的标签值和实际标签值进行对比，得到当前的预测准确率。

5.本次训练结束，保存本批次的损失函数结果和准确率结果，

训练过程中的损失函数和准确率变化如图所示，从图中可以看出，损失函数的值在稳定下降，没有太大的震荡，从准确率变化，可以看出，其实在训练到500Eoph时就可以终止训练了，训练结果已经达到最优了。后面如果再加大训练，可以会引起网络的过度训练，出现过拟合现象。

![image-20200613234703459](C:\Users\zjy\AppData\Roaming\Typora\typora-user-images\image-20200613234703459.png)

## 六、输出数据

训练结果：

![image-20200614000145737](C:\Users\zjy\AppData\Roaming\Typora\typora-user-images\image-20200614000145737.png)

测试数据输出：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190903101611447.png)

对给出的一些数据进行预测：

```python
def iris_prediction(features=[]):

    # 预测函数

    # 加载已经训练好的最优模型（包括网络结构及网络权值矩阵）

    model = tf.keras.models.load_model(
        os.path.join(config.best_model_savepath, "model_best.h5"),
        compile=False)

    # 当预测特征为空时，使用下面给出的默认值进行预测

    if (len(features)==0):
        predFeats = tf.convert_to_tensor([
        [5.9, 3.0, 4.2, 1.5],
        [5.1, 3.3, 1.7, 0.5],
        [6.9, 3.1, 5.4, 2.1]
        ])
    else:

        predFeats = tf.convert_to_tensor(features)

    # 预测结果存放列表

    cat_probs = []

    y_probs = model(predFeats)

    # 取出每条预测结果进行处理，取出其中最大值，即最可能的结果，

    # 根据最大值所在下标，取到cat可读文本

    for prob in y_probs:
        top1 = tf.argmax(prob).numpy()
        cat_probs.append(cat[top1])
    return cat_probs


```

输出结果：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190903101658794.png)

## 七、实验总结

  本次实验中，我首先学习了tensorflow中的一些函数的使用，然后，我对DNN的构造原理，以及如何训练数据、如何使用构建好的模型对数据进行预测。其中，我重新对DNN的网络结构，各层的功能进行了详细的了解，对训练的优化也有了学习。在这个tensorflow官方例子中，通过自己的一步步实现，我对深度神经网络有了进一步的认识。



参考资料：

tensorflow学习之softmax使用详解：

https://blog.csdn.net/u013230189/article/details/82835717?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase

tensorflow官方文档：

https://www.w3cschool.cn/tensorflow_python/


